{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.txt\"\n",
    "raw_text = open(filename, \"r\", encoding = \"utf-8\").read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '#': 4,\n",
       " '$': 5,\n",
       " '%': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " '*': 10,\n",
       " ',': 11,\n",
       " '-': 12,\n",
       " '.': 13,\n",
       " '/': 14,\n",
       " '0': 15,\n",
       " '1': 16,\n",
       " '2': 17,\n",
       " '3': 18,\n",
       " '4': 19,\n",
       " '5': 20,\n",
       " '6': 21,\n",
       " '7': 22,\n",
       " '8': 23,\n",
       " '9': 24,\n",
       " ':': 25,\n",
       " ';': 26,\n",
       " '?': 27,\n",
       " '@': 28,\n",
       " '[': 29,\n",
       " ']': 30,\n",
       " '_': 31,\n",
       " 'a': 32,\n",
       " 'b': 33,\n",
       " 'c': 34,\n",
       " 'd': 35,\n",
       " 'e': 36,\n",
       " 'f': 37,\n",
       " 'g': 38,\n",
       " 'h': 39,\n",
       " 'i': 40,\n",
       " 'j': 41,\n",
       " 'k': 42,\n",
       " 'l': 43,\n",
       " 'm': 44,\n",
       " 'n': 45,\n",
       " 'o': 46,\n",
       " 'p': 47,\n",
       " 'q': 48,\n",
       " 'r': 49,\n",
       " 's': 50,\n",
       " 't': 51,\n",
       " 'u': 52,\n",
       " 'v': 53,\n",
       " 'w': 54,\n",
       " 'x': 55,\n",
       " 'y': 56,\n",
       " 'z': 57}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_int = dict((c,i) for i,c in enumerate(chars))\n",
    "chars_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '\"',\n",
       " 4: '#',\n",
       " 5: '$',\n",
       " 6: '%',\n",
       " 7: \"'\",\n",
       " 8: '(',\n",
       " 9: ')',\n",
       " 10: '*',\n",
       " 11: ',',\n",
       " 12: '-',\n",
       " 13: '.',\n",
       " 14: '/',\n",
       " 15: '0',\n",
       " 16: '1',\n",
       " 17: '2',\n",
       " 18: '3',\n",
       " 19: '4',\n",
       " 20: '5',\n",
       " 21: '6',\n",
       " 22: '7',\n",
       " 23: '8',\n",
       " 24: '9',\n",
       " 25: ':',\n",
       " 26: ';',\n",
       " 27: '?',\n",
       " 28: '@',\n",
       " 29: '[',\n",
       " 30: ']',\n",
       " 31: '_',\n",
       " 32: 'a',\n",
       " 33: 'b',\n",
       " 34: 'c',\n",
       " 35: 'd',\n",
       " 36: 'e',\n",
       " 37: 'f',\n",
       " 38: 'g',\n",
       " 39: 'h',\n",
       " 40: 'i',\n",
       " 41: 'j',\n",
       " 42: 'k',\n",
       " 43: 'l',\n",
       " 44: 'm',\n",
       " 45: 'n',\n",
       " 46: 'o',\n",
       " 47: 'p',\n",
       " 48: 'q',\n",
       " 49: 'r',\n",
       " 50: 's',\n",
       " 51: 't',\n",
       " 52: 'u',\n",
       " 53: 'v',\n",
       " 54: 'w',\n",
       " 55: 'x',\n",
       " 56: 'y',\n",
       " 57: 'z'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char = dict((i,c) for i,c in enumerate(chars))\n",
    "int_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  163780\n",
      "Total Vocab (Unique characters):  58\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab (Unique characters): \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  163765\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers \n",
    "seq_length = 15 #can be changed\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([chars_to_int[char] for char in seq_in])\n",
    "    dataY.append(chars_to_int [seq_out])\n",
    "n_patterns = len(dataY)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.81034483]\n",
      "  [0.84482759]\n",
      "  [0.79310345]\n",
      "  ...\n",
      "  [0.77586207]\n",
      "  [0.56896552]\n",
      "  [0.62068966]]\n",
      "\n",
      " [[0.84482759]\n",
      "  [0.79310345]\n",
      "  [0.70689655]\n",
      "  ...\n",
      "  [0.56896552]\n",
      "  [0.62068966]\n",
      "  [0.84482759]]\n",
      "\n",
      " [[0.79310345]\n",
      "  [0.70689655]\n",
      "  [0.62068966]\n",
      "  ...\n",
      "  [0.62068966]\n",
      "  [0.84482759]\n",
      "  [0.65517241]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.55172414]\n",
      "  [0.56896552]\n",
      "  [0.79310345]\n",
      "  ...\n",
      "  [0.79310345]\n",
      "  [0.79310345]\n",
      "  [0.72413793]]\n",
      "\n",
      " [[0.56896552]\n",
      "  [0.79310345]\n",
      "  [0.89655172]\n",
      "  ...\n",
      "  [0.79310345]\n",
      "  [0.72413793]\n",
      "  [0.86206897]]\n",
      "\n",
      " [[0.79310345]\n",
      "  [0.89655172]\n",
      "  [0.87931034]\n",
      "  ...\n",
      "  [0.72413793]\n",
      "  [0.86206897]\n",
      "  [0.22413793]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.reshape(dataX, (n_patterns,seq_length,1))\n",
    "\n",
    "X = X/float(n_vocab)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163765, 15, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.attention.multi_head_attention import activation \n",
    "from keras.api._v2.keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np_utils.to_categorical(dataY)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]))) #It can have 1 or more training samples \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam')\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint (filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1280/1280 [==============================] - ETA: 0s - loss: 2.9906\n",
      "Epoch 1: loss improved from inf to 2.99056, saving model to weights-improvement-01-2.9906.hdf5\n",
      "1280/1280 [==============================] - 102s 78ms/step - loss: 2.9906\n",
      "Epoch 2/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.8001\n",
      "Epoch 2: loss improved from 2.99056 to 2.80003, saving model to weights-improvement-02-2.8000.hdf5\n",
      "1280/1280 [==============================] - 94s 73ms/step - loss: 2.8000\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - ETA: 0s - loss: 2.7181\n",
      "Epoch 3: loss improved from 2.80003 to 2.71810, saving model to weights-improvement-03-2.7181.hdf5\n",
      "1280/1280 [==============================] - 94s 73ms/step - loss: 2.7181\n",
      "Epoch 4/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.6609\n",
      "Epoch 4: loss improved from 2.71810 to 2.66083, saving model to weights-improvement-04-2.6608.hdf5\n",
      "1280/1280 [==============================] - 89s 70ms/step - loss: 2.6608\n",
      "Epoch 5/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.6182\n",
      "Epoch 5: loss improved from 2.66083 to 2.61814, saving model to weights-improvement-05-2.6181.hdf5\n",
      "1280/1280 [==============================] - 89s 70ms/step - loss: 2.6181\n",
      "Epoch 6/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.5745\n",
      "Epoch 6: loss improved from 2.61814 to 2.57452, saving model to weights-improvement-06-2.5745.hdf5\n",
      "1280/1280 [==============================] - 91s 71ms/step - loss: 2.5745\n",
      "Epoch 7/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.5301\n",
      "Epoch 7: loss improved from 2.57452 to 2.53013, saving model to weights-improvement-07-2.5301.hdf5\n",
      "1280/1280 [==============================] - 81s 63ms/step - loss: 2.5301\n",
      "Epoch 8/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.4866\n",
      "Epoch 8: loss improved from 2.53013 to 2.48645, saving model to weights-improvement-08-2.4865.hdf5\n",
      "1280/1280 [==============================] - 84s 65ms/step - loss: 2.4865\n",
      "Epoch 9/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.4442\n",
      "Epoch 9: loss improved from 2.48645 to 2.44422, saving model to weights-improvement-09-2.4442.hdf5\n",
      "1280/1280 [==============================] - 82s 64ms/step - loss: 2.4442\n",
      "Epoch 10/10\n",
      "1279/1280 [============================>.] - ETA: 0s - loss: 2.4071\n",
      "Epoch 10: loss improved from 2.44422 to 2.40707, saving model to weights-improvement-10-2.4071.hdf5\n",
      "1280/1280 [==============================] - 82s 64ms/step - loss: 2.4071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f9957b700>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'weights-improvement-10-2.4071.hdf5' \n",
    "model.load_weights(filename)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163765\n",
      "129331\n",
      "\" s o - - a n d   w h a t   w i \"\n"
     ]
    }
   ],
   "source": [
    "# generate a random seed\n",
    "print(len(dataX))\n",
    "start = np.random.randint(0, len(dataX)-1) \n",
    "print(start)\n",
    "pattern = dataX[start] #datax contains list of patterns print(\"Seed: \")\n",
    "print(\"\\\"\",' '.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', ' ', 'w', 'o', ' ', 'l', 'e', 'k', 'e', ' ']\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "length = 10\n",
    "final = []\n",
    "for i in range(length):\n",
    "    # reshaping the seed sequence before passing it into the LSTM model\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    #print(x)\n",
    "    # normalizing the integer values\n",
    "    x = x / float(n_vocab)\n",
    "    # print(x)\n",
    "    # making prediction\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    # Get the predicted value with maximum probability \n",
    "    index= np.argmax(prediction)\n",
    "    # Convert the predicted integer to char\n",
    "    result = int_to_char[index]\n",
    "    #print (result)\n",
    "    final.append(result)\n",
    "    # Adding the predicted character to the sequence sequence\n",
    "    pattern.append(index)\n",
    "    # Removing the first character from the seed sequence \n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
